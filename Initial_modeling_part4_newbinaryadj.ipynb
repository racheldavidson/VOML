{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift+enter to execute panels\n",
    "#lines with pound signs are notes or are extra lines of code that were useful at some point and may be useful in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial programs needed to plot and work with numerical data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real data here just means data that isn't toy data for setting up the file\n",
    "#uploads the data from the CSV and fills blanks with 0 \n",
    "df=pd.read_csv(\"real_data_take3b.csv\")\n",
    "df=df.dropna(axis=0, how='all', thresh=None, subset=None, inplace=False)\n",
    "df=df.fillna(value=0)\n",
    "#groups = df.groupby('Phase')\n",
    "\n",
    "#defines or creates a categorical dataset for category-based modeling \n",
    "X = df[['Concentration', 'Time', 'Volume', 'Temperature', 'pH']]\n",
    "y_category = df[['Phase']]\n",
    "y_category=np.ravel(y_category)\n",
    "\n",
    "#defines regression dataset for regression modeling NEEDS PROPER PHASES \n",
    "y_regression = df [['V2O5', 'xerogel', 'V3O7', 'lamellar', 'VO2', 'Z', 'V2O3']]\n",
    "#X_visual = df[['Concentration', 'Time', 'Volume', 'Temperature', 'pH', 'Phase']]\n",
    "y_regression_V2O5= df['V2O5']\n",
    "y_regression_xerogel= df['xerogel']\n",
    "y_regression_V3O7= df['V3O7']\n",
    "y_regression_lamellar= df['lamellar']\n",
    "y_regression_VO2= df['VO2']\n",
    "y_regression_Z= df['Z']\n",
    "y_regression_V2O3= df['V2O3']\n",
    "\n",
    "#to see any of the defined sets above, remove the # from the line below and shift+enter, change the name to a new one as desired\n",
    "#y_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#changes letter to numerical designations of phase because the model requires a number \n",
    "#MUST UPDATE WITH NEW PHASES as they are found \n",
    "\n",
    "df['Phase2']=df['Phase']\n",
    "df['Phase2'].replace(to_replace=['A'], value='1', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['AB'], value='2', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['ABD'], value='3', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['AD'], value='4', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['B'], value='5', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['C'], value='6', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['CD'], value='7', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['CEG'], value='8', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['CE'], value='9', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['D'], value='10', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['E'], value='11', inplace=True)\n",
    "df['Phase2'].replace(to_replace=['F'], value='12', inplace=True)\n",
    "\n",
    "y_category_num = df[['Phase2']]\n",
    "y_category_num=np.ravel(y_category_num)\n",
    "\n",
    "\n",
    "#Concentration, Time, Volume, Temperature, and pH should all be 0-1. This helps model fits not be thrown off by differences in order of magnitude of data.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X[['Concentration', 'Time', 'pH', 'Volume', 'Temperature']] = MinMaxScaler().fit_transform(X[['Concentration', 'Time', 'pH', 'Volume', 'Temperature']])\n",
    "\n",
    "#If a file with X inputs is needed for use in another notebook, use line below\n",
    "#X.to_excel(\"X.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Regressors - One Regressor Each Phase - Just initial fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8470209829610249\n",
      "0.7085398513218074\n",
      "0.8261595914518081\n",
      "0.723599694999849\n",
      "0.9528874679774799\n",
      "-8.722338809229276\n",
      "0.7741025799142665\n"
     ]
    }
   ],
   "source": [
    "#fit and score data as regression for individual classes \n",
    "#This is not the composite model, just the individual regressors\n",
    "#Returns the coefficient of determination R^2 of the prediction.\n",
    "\n",
    "#Imports and defines the model, see sklearn SVM page for details \n",
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "\n",
    "#First line just fits the model/creates the specific model for this case, second creates a score\n",
    "y_rbf_V2O5 = svr_rbf.fit(X, y_regression_V2O5).score\n",
    "y_rbf_V2O5_score = svr_rbf.score(X, y_regression_V2O5)\n",
    "\n",
    "y_rbf_xerogel = svr_rbf.fit(X, y_regression_xerogel)\n",
    "y_rbf_xerogel_score = svr_rbf.score(X, y_regression_xerogel)\n",
    "\n",
    "y_rbf_V3O7 = svr_rbf.fit(X, y_regression_V3O7)\n",
    "y_rbf_V3O7_score = svr_rbf.score(X, y_regression_V3O7)\n",
    "\n",
    "y_rbf_lamellar = svr_rbf.fit(X, y_regression_lamellar)\n",
    "y_rbf_lamellar_score = svr_rbf.score(X, y_regression_lamellar)\n",
    "\n",
    "y_rbf_VO2 = svr_rbf.fit(X, y_regression_VO2)\n",
    "y_rbf_VO2_score = svr_rbf.score(X, y_regression_VO2)\n",
    "\n",
    "y_rbf_V2O3 = svr_rbf.fit(X, y_regression_V2O3)\n",
    "y_rbf_V2O3_score = svr_rbf.score(X, y_regression_V2O3)\n",
    "\n",
    "y_rbf_Z = svr_rbf.fit(X, y_regression_Z)\n",
    "y_rbf_Z_score = svr_rbf.score(X, y_regression_Z)\n",
    "\n",
    "print(y_rbf_V2O5_score)\n",
    "print(y_rbf_xerogel_score)\n",
    "print(y_rbf_V3O7_score)\n",
    "print(y_rbf_lamellar_score)\n",
    "print(y_rbf_VO2_score)\n",
    "print(y_rbf_V2O3_score)\n",
    "print(y_rbf_Z_score)\n",
    "\n",
    "#scores listed are just the R^2 values \n",
    "#most of the fits aren't the worst thing in the world except V2O3 which is terrible because there aren't enough instances of it. So it is fitting a model with input data that doesn't have the feature it is supposed to be fitting to.\n",
    "#These are just fits of model to data scores though, not metrics which show predictivity of the model, which is more telling and shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy V2O5: 0.07 (+/- 0.55)\n",
      "Accuracy Xerogel: -1.31 (+/- 1.70)\n",
      "Accuracy V3O7: -15.22 (+/- 41.94)\n",
      "Accuracy lamellar: -0.82 (+/- 1.54)\n",
      "Accuracy VO2: 0.60 (+/- 0.88)\n",
      "Accuracy V2O3: -15.75 (+/- 44.47)\n",
      "Accuracy Z: -0.06 (+/- 0.17)\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scores show accuracy of models in fitting data that has been left out in building the model. \n",
    "#individual regressors perform extremely poorly\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Creates a cross validation score by pulling out \n",
    "SVR_V2O5_cv = cross_val_score(svr_rbf, X, y_regression_V2O5, cv=3)\n",
    "print(\"Accuracy V2O5: %0.2f (+/- %0.2f)\" % (SVR_V2O5_cv.mean(), SVR_V2O5_cv.std() * 2))                                              \n",
    "SVR_V2O5_cvpred = cross_val_predict(svr_rbf, X, y_regression_V2O5, cv=5)\n",
    "\n",
    "SVR_xerogel_cv = cross_val_score(svr_rbf, X, y_regression_xerogel, cv=3)\n",
    "print(\"Accuracy Xerogel: %0.2f (+/- %0.2f)\" % (SVR_xerogel_cv.mean(), SVR_xerogel_cv.std() * 2))                                                 \n",
    "SVR_xerogel_cvpred = cross_val_predict(svr_rbf, X, y_regression_xerogel, cv=5)\n",
    "\n",
    "SVR_V3O7_cv = cross_val_score(svr_rbf, X, y_regression_V3O7, cv=3)\n",
    "print(\"Accuracy V3O7: %0.2f (+/- %0.2f)\" % (SVR_V3O7_cv.mean(), SVR_V3O7_cv.std() * 2))  \n",
    "SVR_V3O7_cvpred = cross_val_predict(svr_rbf, X, y_regression_V3O7, cv=5)\n",
    "\n",
    "SVR_lamellar_cv = cross_val_score(svr_rbf, X, y_regression_lamellar, cv=3)\n",
    "print(\"Accuracy lamellar: %0.2f (+/- %0.2f)\" % (SVR_lamellar_cv.mean(), SVR_lamellar_cv.std() * 2))  \n",
    "SVR_lamellar_cvpred = cross_val_predict(svr_rbf, X, y_regression_lamellar, cv=5)\n",
    "\n",
    "SVR_VO2_cv = cross_val_score(svr_rbf, X, y_regression_VO2, cv=3)\n",
    "print(\"Accuracy VO2: %0.2f (+/- %0.2f)\" % (SVR_VO2_cv.mean(), SVR_VO2_cv.std() * 2))                                                \n",
    "SVR_VO2_cvpred = cross_val_predict(svr_rbf, X, y_regression_VO2, cv=5)\n",
    "\n",
    "SVR_V2O3_cv = cross_val_score(svr_rbf, X, y_regression_V2O3, cv=3)\n",
    "print(\"Accuracy V2O3: %0.2f (+/- %0.2f)\" % (SVR_V2O3_cv.mean(), SVR_V2O3_cv.std() * 2)) \n",
    "SVR_V2O3_cvpred = cross_val_predict(svr_rbf, X, y_regression_V2O3, cv=5)\n",
    "\n",
    "SVR_Z_cv = cross_val_score(svr_rbf, X, y_regression_Z, cv=3)\n",
    "print(\"Accuracy Z: %0.2f (+/- %0.2f)\" % (SVR_Z_cv.mean(), SVR_Z_cv.std() * 2)) \n",
    "SVR_Z_cvpred = cross_val_predict(svr_rbf, X, y_regression_Z, cv=5)\n",
    "\n",
    "#for svr score is just R^2, so Cross val score is just R2 metric \n",
    "#values would ideallly be from 0-1 indicating accuracy\n",
    "#so now we can see that just the fits of the data to the model are bad with the closest one to a reasonable prediction being VO2\n",
    "\n",
    "#cross val predict would give prediction. For an one-class model, +1 (inlier) or -1 (outlier) is returned.\n",
    "#must convert to accuracy metric \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave one out RMSE single regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR LeaveOneOut V2O5 RMSE 0.42772158271198196\n",
      "SVR LeaveOneOut xerogel RMSE 0.5789259605273643\n",
      "SVR LeaveOneOut V3O7 RMSE 0.31511918192344246\n",
      "SVR LeaveOneOut lamellar RMSE 0.5125374157209966\n",
      "SVR LeaveOneOut VO2 RMSE 0.14383391403600665\n",
      "SVR LeaveOneOut V2O3 RMSE 0.05737015509062139\n",
      "[array([-0.03885693]), array([-0.15574554]), array([-0.00832996]), array([-0.15442303]), array([-0.02977914]), array([0.15566541]), array([-0.00550027]), array([0.15394382]), array([-0.01934666]), array([0.15650403]), array([0.00655168]), array([0.15536701]), array([-0.15035611]), array([0.03240003]), array([-0.14569204]), array([-0.14304544]), array([0.0881571]), array([0.18446467]), array([-0.06805296]), array([0.17385066]), array([0.10346322]), array([0.19491173]), array([-0.05570154]), array([0.18378078]), array([-0.18435024]), array([-0.3183233]), array([-0.09234834]), array([-0.13721592]), array([0.5238427]), array([-0.26795257]), array([-0.25022594]), array([0.04984989]), array([-0.06050223]), array([-0.09373605]), array([0.18266767]), array([0.31709966]), array([-0.05806271]), array([-0.12292587]), array([0.17853311]), array([0.31746292]), array([-0.20485931])]\n",
      "SVR LeaveOneOut Z RMSE 0.29626217682104505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2O5</th>\n",
       "      <th>xerogel</th>\n",
       "      <th>V3O7</th>\n",
       "      <th>lamellar</th>\n",
       "      <th>VO2</th>\n",
       "      <th>V2O3</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.416077</td>\n",
       "      <td>-0.549319</td>\n",
       "      <td>0.548587</td>\n",
       "      <td>0.232648</td>\n",
       "      <td>0.241083</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.038857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259016</td>\n",
       "      <td>0.195915</td>\n",
       "      <td>0.169633</td>\n",
       "      <td>0.114588</td>\n",
       "      <td>0.189365</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.155746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.421189</td>\n",
       "      <td>0.134783</td>\n",
       "      <td>0.104567</td>\n",
       "      <td>0.492502</td>\n",
       "      <td>-0.092078</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.008330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.082491</td>\n",
       "      <td>-0.767162</td>\n",
       "      <td>0.149970</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>-0.067897</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.154423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147560</td>\n",
       "      <td>-0.002104</td>\n",
       "      <td>0.196510</td>\n",
       "      <td>0.620066</td>\n",
       "      <td>0.200898</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.029779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.188435</td>\n",
       "      <td>-0.018988</td>\n",
       "      <td>-0.158439</td>\n",
       "      <td>0.542071</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.155665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944130</td>\n",
       "      <td>0.640587</td>\n",
       "      <td>-0.356782</td>\n",
       "      <td>0.079175</td>\n",
       "      <td>-0.071526</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.224632</td>\n",
       "      <td>-0.333702</td>\n",
       "      <td>0.138059</td>\n",
       "      <td>0.497358</td>\n",
       "      <td>-0.159811</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.153944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.338026</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>-0.074559</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>0.213982</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.019347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.705431</td>\n",
       "      <td>0.529934</td>\n",
       "      <td>0.435871</td>\n",
       "      <td>0.553704</td>\n",
       "      <td>0.200417</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.156504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.684661</td>\n",
       "      <td>0.932299</td>\n",
       "      <td>0.346375</td>\n",
       "      <td>0.362767</td>\n",
       "      <td>-0.164010</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.006552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.329401</td>\n",
       "      <td>0.543187</td>\n",
       "      <td>-0.083573</td>\n",
       "      <td>0.193565</td>\n",
       "      <td>-0.070862</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.155367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.079704</td>\n",
       "      <td>0.274216</td>\n",
       "      <td>0.441079</td>\n",
       "      <td>-0.524201</td>\n",
       "      <td>0.758742</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.150356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.469270</td>\n",
       "      <td>0.293801</td>\n",
       "      <td>0.567973</td>\n",
       "      <td>-0.116453</td>\n",
       "      <td>-0.290297</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.107115</td>\n",
       "      <td>-0.133171</td>\n",
       "      <td>0.057960</td>\n",
       "      <td>0.151146</td>\n",
       "      <td>0.893367</td>\n",
       "      <td>0.01485</td>\n",
       "      <td>-0.145692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.179738</td>\n",
       "      <td>-0.057149</td>\n",
       "      <td>-0.109808</td>\n",
       "      <td>0.089547</td>\n",
       "      <td>-0.121391</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.143045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.102934</td>\n",
       "      <td>0.811723</td>\n",
       "      <td>0.440983</td>\n",
       "      <td>-0.108045</td>\n",
       "      <td>-0.038467</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.088157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.048357</td>\n",
       "      <td>0.743088</td>\n",
       "      <td>0.332926</td>\n",
       "      <td>-0.221092</td>\n",
       "      <td>-0.025471</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.184465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.247169</td>\n",
       "      <td>0.747255</td>\n",
       "      <td>0.192834</td>\n",
       "      <td>-0.445967</td>\n",
       "      <td>0.065357</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.068053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.159568</td>\n",
       "      <td>0.718513</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.173851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.097044</td>\n",
       "      <td>-0.089970</td>\n",
       "      <td>-0.334410</td>\n",
       "      <td>1.004085</td>\n",
       "      <td>-0.025415</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.103463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.415312</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.161515</td>\n",
       "      <td>0.163326</td>\n",
       "      <td>-0.037406</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.194912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.088796</td>\n",
       "      <td>-0.140590</td>\n",
       "      <td>0.076008</td>\n",
       "      <td>0.687664</td>\n",
       "      <td>0.051472</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.055702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.709195</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>-0.280551</td>\n",
       "      <td>0.289598</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.183781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.204205</td>\n",
       "      <td>0.265558</td>\n",
       "      <td>0.208778</td>\n",
       "      <td>-0.098627</td>\n",
       "      <td>0.787993</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.184350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.493609</td>\n",
       "      <td>0.170563</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>0.267880</td>\n",
       "      <td>-0.014363</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.318323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.203928</td>\n",
       "      <td>0.322675</td>\n",
       "      <td>-0.017539</td>\n",
       "      <td>-0.173764</td>\n",
       "      <td>0.806914</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.092348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.357441</td>\n",
       "      <td>-0.119279</td>\n",
       "      <td>0.090915</td>\n",
       "      <td>-0.048117</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.137216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.555822</td>\n",
       "      <td>-0.038966</td>\n",
       "      <td>0.149022</td>\n",
       "      <td>-0.084842</td>\n",
       "      <td>-0.029498</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.523843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.003567</td>\n",
       "      <td>-0.604017</td>\n",
       "      <td>0.450299</td>\n",
       "      <td>0.419616</td>\n",
       "      <td>-0.041488</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.267953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.152879</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>-0.038286</td>\n",
       "      <td>1.565291</td>\n",
       "      <td>-0.016502</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.250226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.598231</td>\n",
       "      <td>0.045564</td>\n",
       "      <td>0.362330</td>\n",
       "      <td>-0.172744</td>\n",
       "      <td>-0.028492</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.049850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.171085</td>\n",
       "      <td>-0.346242</td>\n",
       "      <td>0.071517</td>\n",
       "      <td>0.174776</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.060502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.948340</td>\n",
       "      <td>-0.262822</td>\n",
       "      <td>-0.200409</td>\n",
       "      <td>0.527224</td>\n",
       "      <td>-0.077604</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.093736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.293470</td>\n",
       "      <td>-0.205801</td>\n",
       "      <td>-0.261185</td>\n",
       "      <td>0.478967</td>\n",
       "      <td>0.760764</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.182668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.332451</td>\n",
       "      <td>-0.424656</td>\n",
       "      <td>-0.300855</td>\n",
       "      <td>0.787732</td>\n",
       "      <td>-0.001646</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.286970</td>\n",
       "      <td>0.360611</td>\n",
       "      <td>-0.035518</td>\n",
       "      <td>-0.144327</td>\n",
       "      <td>0.762043</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.058063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.467517</td>\n",
       "      <td>0.553854</td>\n",
       "      <td>-0.171287</td>\n",
       "      <td>0.055156</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.122926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.216047</td>\n",
       "      <td>-0.247271</td>\n",
       "      <td>0.323410</td>\n",
       "      <td>0.172052</td>\n",
       "      <td>0.824957</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.178533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.979255</td>\n",
       "      <td>-0.184310</td>\n",
       "      <td>0.143956</td>\n",
       "      <td>-0.004449</td>\n",
       "      <td>-0.087746</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.317463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.544578</td>\n",
       "      <td>0.125274</td>\n",
       "      <td>-0.213043</td>\n",
       "      <td>0.385742</td>\n",
       "      <td>0.275810</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>-0.204859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        V2O5   xerogel      V3O7  lamellar       VO2     V2O3         Z\n",
       "0   0.416077 -0.549319  0.548587  0.232648  0.241083  0.05665 -0.038857\n",
       "1   0.259016  0.195915  0.169633  0.114588  0.189365  0.05665 -0.155746\n",
       "2   0.421189  0.134783  0.104567  0.492502 -0.092078  0.05665 -0.008330\n",
       "3   1.082491 -0.767162  0.149970  0.545068 -0.067897  0.05665 -0.154423\n",
       "4   0.147560 -0.002104  0.196510  0.620066  0.200898  0.05665 -0.029779\n",
       "5   0.188435 -0.018988 -0.158439  0.542071  0.213885  0.05665  0.155665\n",
       "6   0.944130  0.640587 -0.356782  0.079175 -0.071526  0.05665 -0.005500\n",
       "7   0.224632 -0.333702  0.138059  0.497358 -0.159811  0.05665  0.153944\n",
       "8  -0.338026  0.998486 -0.074559  0.021710  0.213982  0.05665 -0.019347\n",
       "9  -0.705431  0.529934  0.435871  0.553704  0.200417  0.05665  0.156504\n",
       "10 -0.684661  0.932299  0.346375  0.362767 -0.164010  0.05665  0.006552\n",
       "11  0.329401  0.543187 -0.083573  0.193565 -0.070862  0.05665  0.155367\n",
       "12  0.079704  0.274216  0.441079 -0.524201  0.758742  0.05665 -0.150356\n",
       "13  0.469270  0.293801  0.567973 -0.116453 -0.290297  0.05665  0.032400\n",
       "14  0.107115 -0.133171  0.057960  0.151146  0.893367  0.01485 -0.145692\n",
       "15  1.179738 -0.057149 -0.109808  0.089547 -0.121391  0.05665 -0.143045\n",
       "16 -0.102934  0.811723  0.440983 -0.108045 -0.038467  0.05665  0.088157\n",
       "17 -0.048357  0.743088  0.332926 -0.221092 -0.025471  0.05665  0.184465\n",
       "18  0.247169  0.747255  0.192834 -0.445967  0.065357  0.05665 -0.068053\n",
       "19  0.159568  0.718513  0.003965  0.008953  0.051188  0.05665  0.173851\n",
       "20  0.097044 -0.089970 -0.334410  1.004085 -0.025415  0.05665  0.103463\n",
       "21  0.415312  0.094980  0.161515  0.163326 -0.037406  0.05665  0.194912\n",
       "22  0.088796 -0.140590  0.076008  0.687664  0.051472  0.05665 -0.055702\n",
       "23  0.709195  0.054004 -0.280551  0.289598  0.065961  0.05665  0.183781\n",
       "24 -0.204205  0.265558  0.208778 -0.098627  0.787993  0.05665 -0.184350\n",
       "25  0.493609  0.170563  0.095699  0.267880 -0.014363  0.05665 -0.318323\n",
       "26  0.203928  0.322675 -0.017539 -0.173764  0.806914  0.05665 -0.092348\n",
       "27  0.827309  0.357441 -0.119279  0.090915 -0.048117  0.05665 -0.137216\n",
       "28  0.555822 -0.038966  0.149022 -0.084842 -0.029498  0.05665  0.523843\n",
       "29  1.003567 -0.604017  0.450299  0.419616 -0.041488  0.05665 -0.267953\n",
       "30  0.152879  0.050648 -0.038286  1.565291 -0.016502  0.05665 -0.250226\n",
       "31  0.598231  0.045564  0.362330 -0.172744 -0.028492  0.05665  0.049850\n",
       "32  0.171085 -0.346242  0.071517  0.174776  0.823899  0.05665 -0.060502\n",
       "33  0.948340 -0.262822 -0.200409  0.527224 -0.077604  0.05665 -0.093736\n",
       "34 -0.293470 -0.205801 -0.261185  0.478967  0.760764  0.05665  0.182668\n",
       "35  0.332451 -0.424656 -0.300855  0.787732 -0.001646  0.05665  0.317100\n",
       "36  0.286970  0.360611 -0.035518 -0.144327  0.762043  0.05665 -0.058063\n",
       "37  0.467517  0.553854 -0.171287  0.055156  0.029384  0.05665 -0.122926\n",
       "38 -0.216047 -0.247271  0.323410  0.172052  0.824957  0.05665  0.178533\n",
       "39  0.979255 -0.184310  0.143956 -0.004449 -0.087746  0.05665  0.317463\n",
       "40  0.544578  0.125274 -0.213043  0.385742  0.275810  0.05665 -0.204859"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "#creates empty lists that will be filled below\n",
    "loo_pred_V2O5=[]\n",
    "loo_pred_xerogel=[]\n",
    "loo_pred_V3O7=[]\n",
    "loo_pred_lamellar=[]\n",
    "loo_pred_VO2=[]\n",
    "loo_pred_V2O3=[]\n",
    "loo_pred_Z=[]\n",
    "X_array=np.asarray(X)\n",
    "\n",
    "\n",
    "#V2O5 \n",
    "#splits the dataset into test and training datasets, fits a support vector regressor to the training data, predicts y by fitting test data to regressor \n",
    "#This runs as a loop where each loop it adds one more predicted values of y to the empty list\n",
    "for train_index, test_index in loo.split(X_array, y_regression_V2O5):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_regression_V2O5[train_index], y_regression_V2O5[test_index]\n",
    "          \n",
    "    SVR_rbf_V2O5_pred = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "    loo_pred_V2O5.append(SVR_rbf_V2O5_pred)\n",
    "\n",
    "loo_pred_V2O5\n",
    "SVR_loo_V2O5_RMSE = mean_squared_error(y_regression_V2O5, loo_pred_V2O5, squared=False)\n",
    "print(\"SVR LeaveOneOut V2O5 RMSE\", SVR_loo_V2O5_RMSE)\n",
    "\n",
    "#xerogel\n",
    "for train_index, test_index in loo.split(X_array, y_regression_xerogel):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_regression_xerogel[train_index], y_regression_xerogel[test_index]\n",
    "          \n",
    "    SVR_rbf_xerogel_pred = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "    loo_pred_xerogel.append(SVR_rbf_xerogel_pred)\n",
    "\n",
    "loo_pred_xerogel\n",
    "SVR_loo_xerogel_RMSE = mean_squared_error(y_regression_xerogel, loo_pred_xerogel, squared=False)\n",
    "print(\"SVR LeaveOneOut xerogel RMSE\", SVR_loo_xerogel_RMSE)\n",
    "\n",
    "#V3O7\n",
    "for train_index, test_index in loo.split(X_array, y_regression_V3O7):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_regression_V3O7[train_index], y_regression_V3O7[test_index]\n",
    "          \n",
    "    SVR_rbf_V3O7_pred = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "    loo_pred_V3O7.append(SVR_rbf_V3O7_pred)\n",
    "\n",
    "loo_pred_V3O7\n",
    "SVR_loo_V3O7_RMSE = mean_squared_error(y_regression_V3O7, loo_pred_V3O7, squared=False)\n",
    "print(\"SVR LeaveOneOut V3O7 RMSE\", SVR_loo_V3O7_RMSE)\n",
    "\n",
    "#lamellar\n",
    "for train_index, test_index in loo.split(X_array, y_regression_lamellar):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_regression_lamellar[train_index], y_regression_lamellar[test_index]\n",
    "          \n",
    "    SVR_rbf_lamellar_pred = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "    loo_pred_lamellar.append(SVR_rbf_lamellar_pred)\n",
    "\n",
    "loo_pred_lamellar\n",
    "SVR_loo_lamellar_RMSE = mean_squared_error(y_regression_lamellar, loo_pred_lamellar, squared=False)\n",
    "print(\"SVR LeaveOneOut lamellar RMSE\", SVR_loo_lamellar_RMSE)\n",
    "\n",
    "\n",
    "#VO2\n",
    "for train_index, test_index in loo.split(X_array, y_regression_VO2):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_regression_VO2[train_index], y_regression_VO2[test_index]\n",
    "          \n",
    "    SVR_rbf_VO2_pred = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "    loo_pred_VO2.append(SVR_rbf_VO2_pred)\n",
    "\n",
    "loo_pred_VO2\n",
    "SVR_loo_VO2_RMSE = mean_squared_error(y_regression_VO2, loo_pred_VO2, squared=False)\n",
    "print(\"SVR LeaveOneOut VO2 RMSE\", SVR_loo_VO2_RMSE)\n",
    "\n",
    "\n",
    "#V2O3\n",
    "for train_index, test_index in loo.split(X_array, y_regression_V2O3):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_regression_V2O3[train_index], y_regression_V2O3[test_index]\n",
    "          \n",
    "    SVR_rbf_V2O3_pred = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "    loo_pred_V2O3.append(SVR_rbf_V2O3_pred)\n",
    "\n",
    "loo_pred_V2O3\n",
    "SVR_loo_V2O3_RMSE = mean_squared_error(y_regression_V2O3, loo_pred_V2O3, squared=False)\n",
    "print(\"SVR LeaveOneOut V2O3 RMSE\", SVR_loo_V2O3_RMSE)\n",
    "\n",
    "\n",
    "#Z\n",
    "for train_index, test_index in loo.split(X_array, y_regression_Z):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_regression_Z[train_index], y_regression_Z[test_index]\n",
    "          \n",
    "    SVR_rbf_Z_pred = svr_rbf.fit(X_train, y_train).predict(X_test)\n",
    "    loo_pred_Z.append(SVR_rbf_Z_pred)\n",
    "\n",
    "print(loo_pred_Z)\n",
    "SVR_loo_Z_RMSE = mean_squared_error(y_regression_Z, loo_pred_Z, squared=False)\n",
    "print(\"SVR LeaveOneOut Z RMSE\", SVR_loo_Z_RMSE)\n",
    "\n",
    "#Below creates spreadsheet used for additional errror evaluation in Excel \n",
    "OneRegEachPhase_pred_df = pd.DataFrame(np.concatenate(loo_pred_V2O5), columns=['V2O5'])\n",
    "OneRegEachPhase_pred_df['xerogel']= np.concatenate(loo_pred_xerogel)\n",
    "OneRegEachPhase_pred_df['V3O7']= np.concatenate(loo_pred_V3O7)\n",
    "OneRegEachPhase_pred_df['lamellar']= np.concatenate(loo_pred_lamellar)\n",
    "OneRegEachPhase_pred_df['VO2']= np.concatenate(loo_pred_VO2)\n",
    "OneRegEachPhase_pred_df['V2O3']= np.concatenate(loo_pred_V2O3)\n",
    "OneRegEachPhase_pred_df['Z']= np.concatenate(loo_pred_Z)\n",
    "\n",
    "OneRegEachPhase_pred_df.to_excel(\"OneRegEachPhase_pred.xlsx\")\n",
    "OneRegEachPhase_pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15192363158152625\n",
      "0.2761810355867966\n",
      "0.0945916820053276\n",
      "0.27407397201544736\n",
      "0.019267968560921257\n",
      "0.002781068841463415\n",
      "0.08259136464889906\n"
     ]
    }
   ],
   "source": [
    "#rmse is available through sklearn as well \n",
    "#Code below is just for reference in case we wanted to use the sklearn RMSE scores for some reason instead \n",
    "#These currently pull from cross validation predictions rather than leave one out predictions \n",
    "#So the RMSE values should be very different. \n",
    "#If needed below could be re-written as the code in the box above and run as loops \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#mean_squared_error(y_true, y_pred)\n",
    "SVR_V2O5_RMSE = mean_squared_error(y_regression_V2O5, SVR_V2O5_cvpred)\n",
    "print(SVR_V2O5_RMSE)\n",
    "\n",
    "SVR_xerogel_RMSE = mean_squared_error(y_regression_xerogel, SVR_xerogel_cvpred)\n",
    "print(SVR_xerogel_RMSE)\n",
    "\n",
    "SVR_V3O7_RMSE = mean_squared_error(y_regression_V3O7, SVR_V3O7_cvpred)\n",
    "print(SVR_V3O7_RMSE)\n",
    "\n",
    "SVR_lamellar_RMSE = mean_squared_error(y_regression_lamellar, SVR_lamellar_cvpred)\n",
    "print(SVR_lamellar_RMSE)\n",
    "    \n",
    "SVR_VO2_RMSE = mean_squared_error(y_regression_VO2, SVR_VO2_cvpred)\n",
    "print(SVR_VO2_RMSE)\n",
    "    \n",
    "SVR_V2O3_RMSE = mean_squared_error(y_regression_V2O3, SVR_V2O3_cvpred)\n",
    "print(SVR_V2O3_RMSE)\n",
    "    \n",
    "SVR_Z_RMSE = mean_squared_error(y_regression_Z, SVR_Z_cvpred)\n",
    "print(SVR_Z_RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of fitting a regressor to each phase, let's try treating the y as multilabel categories so that the model gets inforamtion on each phase \n",
    "#this is all data formatting but specifically making it multilabel ready \n",
    "\n",
    "#keeps percent compositions-few alogrithms fit this format of the data\n",
    "y_fuzzy = df[['V2O5', 'xerogel', 'V3O7', 'lamellar', 'VO2', 'Z', 'V2O3']]\n",
    "\n",
    "#makes the dataset binary in label category for multiphase\n",
    "y_binary = y_fuzzy.astype(bool).astype(int)\n",
    "\n",
    "#adjusted fuzzy and binary datasets with impurities less than 30% discarded except for columns with only less than 30% presence \n",
    "y_fuzzy_adj=y_fuzzy\n",
    "y_fuzzy_adj['V2O5'].values[df['V2O5'].values<0.3]=0\n",
    "y_fuzzy_adj['xerogel'].values[df['xerogel'].values<0.3]=0\n",
    "y_fuzzy_adj['lamellar'].values[df['lamellar'].values<0.3]=0\n",
    "y_fuzzy_adj['VO2'].values[df['VO2'].values<0.3]=0\n",
    "y_fuzzy_adj['Z'].values[df['Z'].values<0.3]=0\n",
    "y_binary_adj = y_fuzzy_adj.astype(bool).astype(int)\n",
    "\n",
    "#alternatively fuzzy and binary datasets with impurities less than 30% could all be dropped as below\n",
    "#y_fuzzy_adj = y_fuzzy.apply(lambda x: [y if y >= 0.3 else 0 for y in x])\n",
    "#y_binary_adj = y_fuzzy_adj.astype(bool).astype(int)\n",
    "#y_binary_adj = y_binary_adj.drop(columns='V2O3')\n",
    "\n",
    "\n",
    "#first try sklearn classifiers that handle multilabel or multiclass-multioutput \n",
    "#then try metaestimators in sklearn \n",
    "#then try scikitmultilearn packages which are metaestimators? \n",
    "\n",
    "#problem is that no metric currently supported for multioutput multiclass \n",
    "#so there's no easy score... \n",
    "y_binary_adj.to_excel(\"y_binary_adj.xlsx\")\n",
    "\n",
    "#if we want to work with fuzzy data then we would use y_fuzzy or y_fuzzy_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tree_binary: 0.25 (+/- 0.28)\n",
      "Accuracy tree_binary_adj: 0.29 (+/- 0.31)\n",
      "Accuracy knn_category: 0.25 (+/- 0.28)\n",
      "Accuracy knn_binary: 0.15 (+/- 0.24)\n",
      "Accuracy knn_binary_adj: 0.17 (+/- 0.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy forest_category: 0.17 (+/- 0.25)\n",
      "Accuracy forest_binary: 0.12 (+/- 0.16)\n",
      "Accuracy forest_binary_adj: 0.17 (+/- 0.23)\n",
      "Accuracy SVC_category: 0.22 (+/- 0.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy MLP_category: 0.32 (+/- 0.21)\n",
      "Accuracy MLP_binary: 0.12 (+/- 0.16)\n",
      "Accuracy MLP_binary_adj: 0.22 (+/- 0.34)\n"
     ]
    }
   ],
   "source": [
    "#first try sklearn classifiers that handle multilabel or multiclass-multioutput \n",
    "#Code below attempts to fit models 4 ways per model: With categorical y outputs created early in code, binary data\n",
    "#binary adjusted data which drops phases below 30 percent, and original data which has phase percent composition\n",
    "\n",
    "#Where models have # beside them or are not listed, they did not run properly. So these models are incompatible with that specific type of data. \n",
    "#accuracy measured using cross validation, which splits the data into 5 groups and uses 1/5 of the data as a test data each time\n",
    "#this means output values will change slighly depending on how it split the data groups\n",
    "#also means the model only has 4/5 of the data to fit with\n",
    "\n",
    "#decision tree #40, 40, 40\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#category\n",
    "#tree_category = DecisionTreeClassifier(random_state=0).fit(X, y_category)\n",
    "#tree_cv_category = cross_val_score(tree_category, X, y_category, cv=5)\n",
    "#print(\"Accuracy tree_category: %0.2f (+/- %0.2f)\" % (tree_cv_category.mean(), tree_cv_category.std() * 2)) \n",
    "#binary\n",
    "tree_binary = DecisionTreeClassifier(random_state=0).fit(X, y_binary)\n",
    "tree_cv_binary = cross_val_score(tree_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy tree_binary: %0.2f (+/- %0.2f)\" % (tree_cv_binary.mean(), tree_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "tree_binary_adj = DecisionTreeClassifier(criterion='entropy', random_state=0).fit(X, y_binary_adj)\n",
    "tree_cv_binary_adj = cross_val_score(tree_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy tree_binary_adj: %0.2f (+/- %0.2f)\" % (tree_cv_binary_adj.mean(), tree_cv_binary_adj.std() * 2)) \n",
    "#with fuzzy\n",
    "#tree_fuzzy = DecisionTreeClassifier(criterion='entropy', random_state=0).fit(X, y_fuzzy)\n",
    "#tree_cv_fuzzy = cross_val_score(tree_fuzzy, X, y_fuzzy, cv=5)\n",
    "#print(\"Accuracy tree_fuzzy: %0.2f (+/- %0.2f)\" % (tree_cv_fuzzy.mean(), tree_cv_fuzzy.std() * 2)) \n",
    "\n",
    "#KNN #5, 40, 40, \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#category\n",
    "knn_category = KNeighborsClassifier(n_neighbors=7).fit(X, y_category)\n",
    "knn_cv_category = cross_val_score(knn_category, X, y_category, cv=5)\n",
    "print(\"Accuracy knn_category: %0.2f (+/- %0.2f)\" % (knn_cv_category.mean(), knn_cv_category.std() * 2)) \n",
    "#binary\n",
    "knn_binary = KNeighborsClassifier(n_neighbors=5).fit(X, y_binary)\n",
    "knn_cv_binary = cross_val_score(knn_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy knn_binary: %0.2f (+/- %0.2f)\" % (knn_cv_binary.mean(), knn_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "knn_binary_adj = KNeighborsClassifier(n_neighbors=5).fit(X, y_binary_adj)\n",
    "knn_cv_binary_adj = cross_val_score(knn_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy knn_binary_adj: %0.2f (+/- %0.2f)\" % (knn_cv_binary_adj.mean(), knn_cv_binary_adj.std() * 2)) \n",
    "#with fuzzy\n",
    "\n",
    "#RandomForest 5, 5, 5 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#category\n",
    "forest_category = RandomForestClassifier(random_state=0).fit(X, y_category)\n",
    "forest_cv_category = cross_val_score(forest_category, X, y_category, cv=5)\n",
    "print(\"Accuracy forest_category: %0.2f (+/- %0.2f)\" % (forest_cv_category.mean(), forest_cv_category.std() * 2)) \n",
    "#binary\n",
    "forest_binary = RandomForestClassifier(random_state=0).fit(X, y_binary)\n",
    "forest_cv_binary = cross_val_score(forest_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy forest_binary: %0.2f (+/- %0.2f)\" % (forest_cv_binary.mean(), forest_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "forest_binary_adj = RandomForestClassifier(n_estimators=10, random_state=0).fit(X, y_binary_adj)\n",
    "forest_cv_binary_adj = cross_val_score(forest_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy forest_binary_adj: %0.2f (+/- %0.2f)\" % (forest_cv_binary_adj.mean(), forest_cv_binary_adj.std() * 2)) \n",
    "#with fuzzy\n",
    "\n",
    "#SVC 5, 5, 5\n",
    "from sklearn.svm import SVC\n",
    "#category\n",
    "SVC_category = SVC(C=1).fit(X, y_category)\n",
    "SVC_cv_category = cross_val_score(SVC_category, X, y_category, cv=5)\n",
    "print(\"Accuracy SVC_category: %0.2f (+/- %0.2f)\" % (SVC_cv_category.mean(), SVC_cv_category.std() * 2)) \n",
    "#binary\n",
    "#SVC_binary = SVC(C=1).fit(X, y_binary)\n",
    "#SVC_cv_binary = cross_val_score(SVC_binary, X, y_binary, cv=5)\n",
    "#print(\"Accuracy SVC_binary: %0.2f (+/- %0.2f)\" % (SVC_cv_binary.mean(), SVC_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "#SVC_binary_adj = SVC(C=1).fit(X, y_binary_adj)\n",
    "#SVC_cv_binary_adj = cross_val_score(SVC_binary_adj, X, y_binary_adj, cv=5)\n",
    "#print(\"Accuracy SVC_binary_adj: %0.2f (+/- %0.2f)\" % (SVC_cv_binary_adj.mean(), SVC_cv_binary_adj.std() * 2))    \n",
    "#with fuzzy\n",
    "\n",
    "#neural network 5, 40, 40\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#category\n",
    "MLP_category = MLPClassifier(max_iter=300, solver='lbfgs').fit(X, y_category_num)\n",
    "MLP_cv_category = cross_val_score(MLP_category, X, y_category_num, cv=5)\n",
    "print(\"Accuracy MLP_category: %0.2f (+/- %0.2f)\" % (MLP_cv_category.mean(), MLP_cv_category.std() * 2)) \n",
    "#binary\n",
    "MLP_binary = MLPClassifier(max_iter=300, solver='lbfgs').fit(X, y_binary)\n",
    "MLP_cv_binary = cross_val_score(MLP_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy MLP_binary: %0.2f (+/- %0.2f)\" % (MLP_cv_binary.mean(), MLP_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "MLP_binary_adj = MLPClassifier(max_iter=300, solver='lbfgs').fit(X, y_binary_adj)\n",
    "MLP_cv_binary_adj = cross_val_score(MLP_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy MLP_binary_adj: %0.2f (+/- %0.2f)\" % (MLP_cv_binary_adj.mean(), MLP_cv_binary_adj.std() * 2)) \n",
    "#with fuzzy\n",
    "\n",
    "\n",
    "#tree_binary_adj has accuracy 25% \n",
    "#knn_category has accuracy 25%\n",
    "#MLP_category has accuracy 34% \n",
    "#These are re-run with leave one out error metrics later. \n",
    "#also the supported multiclass-multioutput category doesn't work with continous variables. So it wants categories of categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tree_OVR_cv_category: 0.15 (+/- 0.19)\n",
      "Accuracy tree_OVR_cv_binary: 0.22 (+/- 0.34)\n",
      "Accuracy tree_OVR_cv_binary_adj: 0.17 (+/- 0.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy knn_OVR_category: 0.22 (+/- 0.19)\n",
      "Accuracy knn_OVR_binary: 0.15 (+/- 0.24)\n",
      "Accuracy knn_OVR_binary_adj: 0.17 (+/- 0.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy forest_OVR_category: 0.25 (+/- 0.23)\n",
      "Accuracy forest_OVR_binary: 0.17 (+/- 0.30)\n",
      "Accuracy forest_OVR_binary_adj: 0.15 (+/- 0.24)\n",
      "Accuracy SVC_OVR_cv_category: 0.29 (+/- 0.26)\n",
      "Accuracy SVC_OVR_cv_binary: 0.17 (+/- 0.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVC_OVR_cv_binary_adj: 0.19 (+/- 0.20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.22222222, 0.25      , 0.        , 0.25      , 0.25      ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then try metaestimators in sklearn \n",
    "#One vs rest classifiers fit one classifier for each class \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "#decision tree\n",
    "#category 5, 5, 5 \n",
    "tree_OVR_category = OneVsRestClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_category)\n",
    "tree_OVR_cv_category = cross_val_score(tree_OVR_category, X, y_category, cv=5)\n",
    "print(\"Accuracy tree_OVR_cv_category: %0.2f (+/- %0.2f)\" % (tree_OVR_cv_category.mean(), tree_OVR_cv_category.std() * 2)) \n",
    "#binary\n",
    "tree_OVR_binary = OneVsRestClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_binary)\n",
    "tree_OVR_cv_binary = cross_val_score(tree_OVR_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy tree_OVR_cv_binary: %0.2f (+/- %0.2f)\" % (tree_OVR_cv_binary.mean(), tree_OVR_cv_binary.std() * 2)) \n",
    "#binary_adj\n",
    "tree_OVR_binary_adj = OneVsRestClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_binary_adj)\n",
    "tree_OVR_cv_binary_adj = cross_val_score(tree_OVR_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy tree_OVR_cv_binary_adj: %0.2f (+/- %0.2f)\" % (tree_OVR_cv_binary_adj.mean(), tree_OVR_cv_binary_adj.std() * 2)) \n",
    "tree_OVR_cv_binary_adj\n",
    "\n",
    "#KNN\n",
    "#category 5, 40, 40\n",
    "knn_OVR_category = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=7)).fit(X, y_category)\n",
    "knn_OVR_cv_category = cross_val_score(knn_OVR_category, X, y_category, cv=5)\n",
    "print(\"Accuracy knn_OVR_category: %0.2f (+/- %0.2f)\" % (knn_OVR_cv_category.mean(), knn_OVR_cv_category.std() * 2)) \n",
    "#binary\n",
    "knn_OVR_binary = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X, y_binary)\n",
    "knn_OVR_cv_binary = cross_val_score(knn_OVR_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy knn_OVR_binary: %0.2f (+/- %0.2f)\" % (knn_OVR_cv_binary.mean(), knn_OVR_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "knn_OVR_binary_adj = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X, y_binary_adj)\n",
    "knn_OVR_cv_binary_adj = cross_val_score(knn_OVR_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy knn_OVR_binary_adj: %0.2f (+/- %0.2f)\" % (knn_OVR_cv_binary_adj.mean(), knn_OVR_cv_binary_adj.std() * 2)) \n",
    "\n",
    "#RandomForest\n",
    "#category 5, 5, 5\n",
    "forest_OVR_category = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_category)\n",
    "forest_OVR_cv_category = cross_val_score(forest_OVR_category, X, y_category, cv=5)\n",
    "print(\"Accuracy forest_OVR_category: %0.2f (+/- %0.2f)\" % (forest_OVR_cv_category.mean(), forest_OVR_cv_category.std() * 2)) \n",
    "#binary\n",
    "forest_OVR_binary = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_binary)\n",
    "forest_OVR_cv_binary = cross_val_score(forest_OVR_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy forest_OVR_binary: %0.2f (+/- %0.2f)\" % (forest_OVR_cv_binary.mean(), forest_OVR_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "forest_OVR_binary_adj = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_binary_adj)\n",
    "forest_OVR_cv_binary_adj = cross_val_score(forest_OVR_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy forest_OVR_binary_adj: %0.2f (+/- %0.2f)\" % (forest_OVR_cv_binary_adj.mean(), forest_OVR_cv_binary_adj.std() * 2))\n",
    "\n",
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "#category 5, 5, 5\n",
    "SVC_OVR_category = OneVsRestClassifier(SVC()).fit(X, y_category)\n",
    "SVC_OVR_cv_category = cross_val_score(SVC_OVR_category, X, y_category, cv=5)\n",
    "print(\"Accuracy SVC_OVR_cv_category: %0.2f (+/- %0.2f)\" % (SVC_OVR_cv_category.mean(), SVC_OVR_cv_category.std() * 2)) \n",
    "#binary\n",
    "SVC_OVR_binary = OneVsRestClassifier(SVC()).fit(X, y_binary)\n",
    "SVC_OVR_cv_binary = cross_val_score(SVC_OVR_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy SVC_OVR_cv_binary: %0.2f (+/- %0.2f)\" % (SVC_OVR_cv_binary.mean(), SVC_OVR_cv_binary.std() * 2)) \n",
    "#binary_adj\n",
    "SVC_OVR_binary_adj = OneVsRestClassifier(SVC()).fit(X, y_binary_adj)\n",
    "SVC_OVR_cv_binary_adj = cross_val_score(SVC_OVR_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy SVC_OVR_cv_binary_adj: %0.2f (+/- %0.2f)\" % (SVC_OVR_cv_binary_adj.mean(), SVC_OVR_cv_binary_adj.std() * 2)) \n",
    "SVC_OVR_cv_binary_adj\n",
    "\n",
    "#SVR OVR accuracy 29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tree_OVO_cv_category: 0.17 (+/- 0.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy forest_OVO_category: 0.27 (+/- 0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raera\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVC_OVO_cv_category: 0.22 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "#then try metaestimators in sklearn \n",
    "#One vs one classifiers\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "#decision tree\n",
    "#category\n",
    "tree_OVO_category = OneVsOneClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_category)\n",
    "tree_OVO_cv_category = cross_val_score(tree_OVO_category, X, y_category, cv=5)\n",
    "print(\"Accuracy tree_OVO_cv_category: %0.2f (+/- %0.2f)\" % (tree_OVO_cv_category.mean(), tree_OVO_cv_category.std() * 2)) \n",
    "#binary\n",
    "#tree_OVO_binary = OneVsOneClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_binary)\n",
    "#tree_OVO_cv_binary = cross_val_score(tree_OVO_binary, X, y_binary, cv=5)\n",
    "#print(\"Accuracy tree_OVO_cv_binary: %0.2f (+/- %0.2f)\" % (tree_OVO_cv_binary.mean(), tree_OVO_cv_binary.std() * 2)) \n",
    "#binary_adj\n",
    "#tree_OVO_binary_adj = OneVsOneClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_binary_adj)\n",
    "#tree_OVO_cv_binary_adj = cross_val_score(tree_OVO_binary_adj, X, y_binary_adj, cv=5)\n",
    "#print(\"Accuracy tree_OVO_cv_binary_adj: %0.2f (+/- %0.2f)\" % (tree_OVO_cv_binary_adj.mean(), tree_OVO_cv_binary_adj.std() * 2)) \n",
    "#tree_OVO_cv_binary_adj\n",
    "\n",
    "#KNN\n",
    "#category\n",
    "#knn_OVO_category = OneVsOneClassifier(KNeighborsClassifier(n_neighbors=7)).fit(X, y_category)\n",
    "#knn_OVO_cv_category = cross_val_score(knn_OVO_category, X, y_category, cv=5)\n",
    "#print(\"Accuracy knn_OVO_category: %0.2f (+/- %0.2f)\" % (knn_OVO_cv_category.mean(), knn_OVO_cv_category.std() * 2)) \n",
    "#binary\n",
    "#knn_OVO_binary = OneVsOneClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X, y_binary)\n",
    "#knn_OVO_cv_binary = cross_val_score(knn_OVO_binary, X, y_binary, cv=40)\n",
    "#print(\"Accuracy knn_OVO_binary: %0.2f (+/- %0.2f)\" % (knn_OVO_cv_binary.mean(), knn_OVO_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "#knn_OVO_binary_adj = OneVsOneClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X, y_binary_adj)\n",
    "#knn_OVO_cv_binary_adj = cross_val_score(knn_OVO_binary_adj, X, y_binary_adj, cv=40)\n",
    "#print(\"Accuracy knn_OVO_binary_adj: %0.2f (+/- %0.2f)\" % (knn_OVO_cv_binary_adj.mean(), knn_OVO_cv_binary_adj.std() * 2)) \n",
    "\n",
    "#RandomForest\n",
    "#category\n",
    "forest_OVO_category = OneVsOneClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_category)\n",
    "forest_OVO_cv_category = cross_val_score(forest_OVO_category, X, y_category, cv=5)\n",
    "print(\"Accuracy forest_OVO_category: %0.2f (+/- %0.2f)\" % (forest_OVO_cv_category.mean(), forest_OVO_cv_category.std() * 2)) \n",
    "#binary\n",
    "#forest_OVO_binary = OneVsOneClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_binary)\n",
    "#forest_OVO_cv_binary = cross_val_score(forest_OVO_binary, X, y_binary, cv=5)\n",
    "#print(\"Accuracy forest_OVO_binary: %0.2f (+/- %0.2f)\" % (forest_OVO_cv_binary.mean(), forest_OVO_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "#forest_OVO_binary_adj = OneVsOneClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_binary_adj)\n",
    "#forest_OVO_cv_binary_adj = cross_val_score(forest_OVO_binary_adj, X, y_binary_adj, cv=5)\n",
    "#print(\"Accuracy forest_OVO_binary_adj: %0.2f (+/- %0.2f)\" % (forest_OVO_cv_binary_adj.mean(), forest_OVO_cv_binary_adj.std() * 2))\n",
    "\n",
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "#category\n",
    "SVC_OVO_category = OneVsOneClassifier(SVC()).fit(X, y_category)\n",
    "SVC_OVO_cv_category = cross_val_score(SVC_OVO_category, X, y_category, cv=5)\n",
    "print(\"Accuracy SVC_OVO_cv_category: %0.2f (+/- %0.2f)\" % (SVC_OVO_cv_category.mean(), SVC_OVO_cv_category.std() * 2)) \n",
    "#binary\n",
    "#SVC_OVO_binary = OneVsOneClassifier(SVC()).fit(X, y_binary)\n",
    "#SVC_OVO_cv_binary = cross_val_score(SVC_OVO_binary, X, y_binary, cv=5)\n",
    "#print(\"Accuracy SVC_OVO_cv_binary: %0.2f (+/- %0.2f)\" % (SVC_OVO_cv_binary.mean(), SVC_OVO_cv_binary.std() * 2)) \n",
    "#binary_adj\n",
    "#SVC_OVO_binary_adj = OneVsOneClassifier(SVC()).fit(X, y_binary_adj)\n",
    "#SVC_OVO_cv_binary_adj = cross_val_score(SVC_OVO_binary_adj, X, y_binary_adj, cv=5)\n",
    "#print(\"Accuracy SVC_OVO_cv_binary_adj: %0.2f (+/- %0.2f)\" % (SVC_OVO_cv_binary_adj.mean(), SVC_OVO_cv_binary_adj.std() * 2)) \n",
    "#SVC_OVO_cv_binary_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tree_MOC_cv_binary: 0.22 (+/- 0.34)\n",
      "Accuracy tree_MOC_cv_binary_adj: 0.17 (+/- 0.13)\n",
      "Accuracy knn_MOC_binary: 0.12 (+/- 0.66)\n",
      "Accuracy knn_MOC_binary_adj: 0.12 (+/- 0.66)\n",
      "Accuracy forest_MOC_binary: 0.17 (+/- 0.30)\n",
      "Accuracy forest_MOC_binary_adj: 0.15 (+/- 0.24)\n",
      "Accuracy SVC_MOC_cv_binary: 0.17 (+/- 0.30)\n",
      "Accuracy SVC_MOC_cv_binary_adj: 0.19 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "#scikit multioutput classification \n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "#multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1).fit(X, y_fuzzy)\n",
    "\n",
    "#decision tree\n",
    "#binary\n",
    "tree_MOC_binary = MultiOutputClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_binary)\n",
    "tree_MOC_cv_binary = cross_val_score(tree_MOC_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy tree_MOC_cv_binary: %0.2f (+/- %0.2f)\" % (tree_MOC_cv_binary.mean(), tree_MOC_cv_binary.std() * 2)) \n",
    "#binary_adj\n",
    "tree_MOC_binary_adj = MultiOutputClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_binary_adj)\n",
    "tree_MOC_cv_binary_adj = cross_val_score(tree_MOC_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy tree_MOC_cv_binary_adj: %0.2f (+/- %0.2f)\" % (tree_MOC_cv_binary_adj.mean(), tree_MOC_cv_binary_adj.std() * 2)) \n",
    "#fuzzy\n",
    "#tree_MOC_fuzzy = MultiOutputClassifier(DecisionTreeClassifier(random_state=0)).fit(X, y_fuzzy)\n",
    "#tree_MOC_cv_fuzzy = cross_val_score(tree_MOC_fuzzy, X, y_fuzzy, cv=5)\n",
    "#print(\"Accuracy tree_MOC_cv_fuzzy: %0.2f (+/- %0.2f)\" % (tree_MOC_cv_fuzzy.mean(), tree_MOC_cv_fuzzy.std() * 2)) \n",
    "\n",
    "#KNN\n",
    "#binary\n",
    "knn_MOC_binary = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X, y_binary)\n",
    "knn_MOC_cv_binary = cross_val_score(knn_MOC_binary, X, y_binary, cv=40)\n",
    "print(\"Accuracy knn_MOC_binary: %0.2f (+/- %0.2f)\" % (knn_MOC_cv_binary.mean(), knn_MOC_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "knn_MOC_binary_adj = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X, y_binary_adj)\n",
    "knn_MOC_cv_binary_adj = cross_val_score(knn_MOC_binary_adj, X, y_binary_adj, cv=40)\n",
    "print(\"Accuracy knn_MOC_binary_adj: %0.2f (+/- %0.2f)\" % (knn_MOC_cv_binary_adj.mean(), knn_MOC_cv_binary_adj.std() * 2)) \n",
    "\n",
    "#RandomForest\n",
    "#binary\n",
    "forest_MOC_binary = MultiOutputClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_binary)\n",
    "forest_MOC_cv_binary = cross_val_score(forest_MOC_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy forest_MOC_binary: %0.2f (+/- %0.2f)\" % (forest_MOC_cv_binary.mean(), forest_MOC_cv_binary.std() * 2)) \n",
    "#with adjusted binary\n",
    "forest_MOC_binary_adj = MultiOutputClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X, y_binary_adj)\n",
    "forest_MOC_cv_binary_adj = cross_val_score(forest_MOC_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy forest_MOC_binary_adj: %0.2f (+/- %0.2f)\" % (forest_MOC_cv_binary_adj.mean(), forest_MOC_cv_binary_adj.std() * 2))\n",
    "\n",
    "#SVC\n",
    "#binary\n",
    "SVC_MOC_binary = MultiOutputClassifier(SVC()).fit(X, y_binary)\n",
    "SVC_MOC_cv_binary = cross_val_score(SVC_MOC_binary, X, y_binary, cv=5)\n",
    "print(\"Accuracy SVC_MOC_cv_binary: %0.2f (+/- %0.2f)\" % (SVC_MOC_cv_binary.mean(), SVC_MOC_cv_binary.std() * 2)) \n",
    "#binary_adj\n",
    "SVC_MOC_binary_adj = MultiOutputClassifier(SVC()).fit(X, y_binary_adj)\n",
    "SVC_MOC_cv_binary_adj = cross_val_score(SVC_MOC_binary_adj, X, y_binary_adj, cv=5)\n",
    "print(\"Accuracy SVC_MOC_cv_binary_adj: %0.2f (+/- %0.2f)\" % (SVC_MOC_cv_binary_adj.mean(), SVC_MOC_cv_binary_adj.std() * 2)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOutError [0.14634146 0.17073171 0.2195122  0.12195122 0.14634146 0.19512195\n",
      " 0.17073171 0.07317073 0.14634146 0.2195122  0.26829268]\n",
      "LeaveOneOutStd [0.35344821 0.37627436 0.41391616 0.32722946 0.35344821 0.39629456\n",
      " 0.37627436 0.26041654 0.35344821 0.41391616 0.44307078]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "loo = LeaveOneOut()\n",
    "loo_errors_category=[[], [], [], [], [], [], [], [], [], [], []]\n",
    "X_array=np.asarray(X)\n",
    "        \n",
    "for train_index, test_index in loo.split(X_array, y_category_num):\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_category_num[train_index], y_category_num[test_index]\n",
    "          \n",
    "    knn_loo_category = KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[0].append(knn_loo_category)\n",
    "            \n",
    "    forest_loo_category = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[1].append(forest_loo_category)\n",
    "            \n",
    "    SVC_loo_category = SVC(C=1).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[2].append(SVC_loo_category)\n",
    "    \n",
    "    tree_loo_OVR_category = OneVsRestClassifier(DecisionTreeClassifier(random_state=0)).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[3].append(tree_loo_OVR_category)\n",
    "    \n",
    "    knn_loo_OVR_category = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=7)).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[4].append(knn_loo_OVR_category)\n",
    "    \n",
    "    forest_loo_OVR_category = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[5].append(forest_loo_OVR_category)\n",
    "    \n",
    "    SVC_loo_OVR_category = OneVsRestClassifier(SVC()).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[6].append(SVC_loo_OVR_category)\n",
    "    \n",
    "    tree_loo_OVO_category = OneVsOneClassifier(DecisionTreeClassifier(random_state=0)).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[7].append(tree_loo_OVO_category)\n",
    "    \n",
    "    forest_loo_OVO_category = OneVsOneClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[8].append(forest_loo_OVO_category)\n",
    "    \n",
    "    SVC_loo_OVO_category = OneVsOneClassifier(SVC()).fit(X, y_category).fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[9].append(SVC_loo_OVO_category)\n",
    "    \n",
    "    MLP_loo_category = MLPClassifier(max_iter=300, solver='lbfgs').fit(X_train, y_train).score(X_test, y_test)\n",
    "    loo_errors_category[10].append(MLP_loo_category)\n",
    "    \n",
    "loo_errors_mean=np.mean(loo_errors_category, axis=1)\n",
    "loo_errors_std=np.std(loo_errors_category, axis=1)\n",
    "#print(loo_errors_mean[0])\n",
    "#print(loo_errors_mean[1])\n",
    "#print(loo_errors_mean[2])\n",
    "#print(\"LeaveOneOut Error Knn: %0.2f (+/- %0.2f)\" % (loo_error.mean(), MLP_cv_binary_adj.std() * 2))\n",
    "print(\"LeaveOneOutError\", loo_errors_mean)\n",
    "print(\"LeaveOneOutStd\", loo_errors_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOutError [0.14634146 0.09756098 0.04878049 0.12195122 0.17073171 0.12195122\n",
      " 0.14634146 0.12195122]\n",
      "LeaveOneOutStd [0.35344821 0.29672012 0.2154088  0.32722946 0.37627436 0.32722946\n",
      " 0.35344821 0.32722946]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "loo_errors_binary=[[], [], [], [], [], [], [], []]\n",
    "X_array=np.asarray(X)\n",
    "y_binary_array=np.asarray(y_binary)\n",
    "\n",
    "for train_index, test_index in loo.split(X_array, y_binary_array):\n",
    "    X_train_b, X_test_b = X_array[train_index], X_array[test_index]\n",
    "    y_train_b, y_test_b = y_binary_array[train_index], y_binary_array[test_index]\n",
    "          \n",
    "    tree_loo_binary = DecisionTreeClassifier(random_state=0).fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[0].append(tree_loo_binary)\n",
    "    \n",
    "    knn_loo_binary = KNeighborsClassifier(n_neighbors=7).fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[1].append(knn_loo_binary)\n",
    "            \n",
    "    forest_loo_binary = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[2].append(forest_loo_binary)\n",
    "            \n",
    "    MLP_loo_binary = MLPClassifier(max_iter=300, solver='lbfgs').fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[3].append(MLP_loo_binary)\n",
    "    \n",
    "    tree_loo_OVR_binary = OneVsRestClassifier(DecisionTreeClassifier(random_state=0)).fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[4].append(tree_loo_OVR_binary)\n",
    "    \n",
    "    knn_loo_OVR_binary = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[5].append(knn_loo_OVR_binary)\n",
    "    \n",
    "    forest_loo_OVR_binary = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[6].append(forest_loo_OVR_binary)\n",
    "    \n",
    "    SVC_loo_OVR_binary = OneVsRestClassifier(SVC()).fit(X_train_b, y_train_b).score(X_test_b, y_test_b)\n",
    "    loo_errors_binary[7].append(SVC_loo_OVR_binary)\n",
    "    \n",
    "    \n",
    "loo_errors_binary_mean=np.mean(loo_errors_binary, axis=1)\n",
    "loo_errors_binary_std=np.std(loo_errors_binary, axis=1)\n",
    "#print(loo_errors_mean[0])\n",
    "#print(loo_errors_mean[1])\n",
    "#print(loo_errors_mean[2])\n",
    "#print(\"LeaveOneOut Error Knn: %0.2f (+/- %0.2f)\" % (loo_error.mean(), MLP_cv_binary_adj.std() * 2))\n",
    "print(\"LeaveOneOutError\", loo_errors_binary_mean)\n",
    "print(\"LeaveOneOutStd\", loo_errors_binary_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeaveOneOutError [0.29268293 0.14634146 0.         0.2195122  0.12195122 0.12195122\n",
      " 0.12195122 0.17073171]\n",
      "LeaveOneOutStd [0.4549941  0.35344821 0.         0.41391616 0.32722946 0.32722946\n",
      " 0.32722946 0.37627436]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "loo_errors_binary_adj=[[], [], [], [], [], [], [], []]\n",
    "X_array=np.asarray(X)\n",
    "y_binary_adj_array=np.asarray(y_binary_adj)\n",
    "\n",
    "for train_index, test_index in loo.split(X_array, y_binary_adj_array):\n",
    "    X_train_ba, X_test_ba = X_array[train_index], X_array[test_index]\n",
    "    y_train_ba, y_test_ba = y_binary_adj_array[train_index], y_binary_adj_array[test_index]\n",
    "          \n",
    "    tree_loo_binary_adj = DecisionTreeClassifier(random_state=0).fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[0].append(tree_loo_binary_adj)\n",
    "    \n",
    "    knn_loo_binary_adj = KNeighborsClassifier(n_neighbors=7).fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[1].append(knn_loo_binary_adj)\n",
    "            \n",
    "    forest_loo_binary_adj = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[2].append(forest_loo_binary_adj)\n",
    "            \n",
    "    MLP_loo_binary_adj = MLPClassifier(max_iter=300, solver='lbfgs').fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[3].append(MLP_loo_binary_adj)\n",
    "    \n",
    "    tree_loo_OVR_binary_adj = OneVsRestClassifier(DecisionTreeClassifier(random_state=0)).fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[4].append(tree_loo_OVR_binary_adj)\n",
    "    \n",
    "    knn_loo_OVR_binary_adj = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=5)).fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[5].append(knn_loo_OVR_binary_adj)\n",
    "    \n",
    "    forest_loo_OVR_binary_adj = OneVsRestClassifier(RandomForestClassifier(max_depth=2, random_state=0)).fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[6].append(forest_loo_OVR_binary_adj)\n",
    "    \n",
    "    SVC_loo_OVR_binary_adj = OneVsRestClassifier(SVC()).fit(X, y_binary_adj).fit(X_train_ba, y_train_ba).score(X_test_ba, y_test_ba)\n",
    "    loo_errors_binary_adj[7].append(SVC_loo_OVR_binary_adj)\n",
    "    \n",
    "loo_errors_binary_adj_mean=np.mean(loo_errors_binary_adj, axis=1)\n",
    "loo_errors_binary_adj_std=np.std(loo_errors_binary_adj, axis=1)\n",
    "#print(loo_errors_mean[0])\n",
    "#print(loo_errors_mean[1])\n",
    "#print(loo_errors_mean[2])\n",
    "#print(\"LeaveOneOut Error Knn: %0.2f (+/- %0.2f)\" % (loo_error.mean(), MLP_cv_binary_adj.std() * 2))\n",
    "print(\"LeaveOneOutError\", loo_errors_binary_adj_mean)\n",
    "print(\"LeaveOneOutStd\", loo_errors_binary_adj_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(loo_errors_binary_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table showing all samples we could sample, including those we already have\n",
    "#this is also minmaxscaled\n",
    "import itertools\n",
    "Concentration= [0.1, 0.3, 0.5]\n",
    "Time= [1, 2.5, 4]\n",
    "Volume= [8, 12, 16]\n",
    "Temperature= [200, 225, 250]\n",
    "#average of initial pH of solution \n",
    "pH= [0.54, 1.54, 2.54]\n",
    "full_factorial=list(map(list, itertools.product(Concentration, Time, Volume, Temperature, pH)))\n",
    "len(full_factorial)\n",
    "full_factorialpd=pd.DataFrame(full_factorial, columns=('Concentration', 'Time', 'Volume', 'Temperature', 'pH'))\n",
    "\n",
    "\n",
    "full_factorialpd[['Concentration','Time', 'pH', 'Volume', 'Temperature']] = MinMaxScaler().fit_transform(full_factorialpd[['Concentration', 'Time', 'pH', 'Volume', 'Temperature']])\n",
    "full_factorialpd\n",
    "full_factorialpd.to_excel(\"full_factorialpd.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.5]\n",
      " [0.  0.  0.  0.  1. ]\n",
      " ...\n",
      " [1.  1.  1.  1.  0. ]\n",
      " [1.  1.  1.  1.  0.5]\n",
      " [1.  1.  1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "learner_1 = ActiveLearner(estimator=DecisionTreeClassifier(random_state=0), query_strategy=uncertainty_sampling, X_training=X_array, y_training=y_binary_adj)\n",
    "\n",
    "#learner_2 = ActiveLearner(estimator=KNeighborsClassifier(n_neighbors=7), query_strategy=uncertainty_sampling, X_training=X, y_training=y_binary_adj)\n",
    "\n",
    "# querying for labels\n",
    "full_factorialarray=full_factorialpd.values\n",
    "print(full_factorialarray)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4, 4],\n",
       "        [3, 3],\n",
       "        [5, 5],\n",
       "        [0, 0],\n",
       "        [2, 2],\n",
       "        [1, 1]], dtype=int64),\n",
       " array([[[0. , 0. , 0. , 0.5, 0.5],\n",
       "         [0. , 0. , 0. , 0.5, 0.5]],\n",
       " \n",
       "        [[0. , 0. , 0. , 0.5, 0. ],\n",
       "         [0. , 0. , 0. , 0.5, 0. ]],\n",
       " \n",
       "        [[0. , 0. , 0. , 0.5, 1. ],\n",
       "         [0. , 0. , 0. , 0.5, 1. ]],\n",
       " \n",
       "        [[0. , 0. , 0. , 0. , 0. ],\n",
       "         [0. , 0. , 0. , 0. , 0. ]],\n",
       " \n",
       "        [[0. , 0. , 0. , 0. , 1. ],\n",
       "         [0. , 0. , 0. , 0. , 1. ]],\n",
       " \n",
       "        [[0. , 0. , 0. , 0. , 0.5],\n",
       "         [0. , 0. , 0. , 0. , 0.5]]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idx, query_sample = learner_1.query(full_factorialarray, n_instances=6)\n",
    "\n",
    "#query_sample\n",
    "query_idx, query_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
